# backend/Dockerfile.worker
# Cloud worker image with SAM3 model baked in
#
# Build:
#   DOCKER_BUILDKIT=1 docker build --platform linux/amd64 -f Dockerfile.worker -t basketball-analyzer-worker .
#
# Run:
#   docker run --gpus all -e R2_ACCOUNT_ID=xxx -e R2_ACCESS_KEY_ID=xxx \
#     -e R2_SECRET_ACCESS_KEY=xxx -e R2_BUCKET_NAME=xxx \
#     basketball-analyzer-worker

# ============================================================================
# Stage 1: Export requirements from poetry (small, fast, cached)
# ============================================================================
FROM python:3.11-slim AS requirements

WORKDIR /build
RUN pip install poetry poetry-plugin-export

COPY pyproject.toml poetry.lock* ./
RUN poetry export --only main,ml,video --without-hashes -f requirements.txt -o requirements.txt
# Note: excludes api group (fastapi, uvicorn, alembic, rfdetr, norfair, runpod)

# ============================================================================
# Stage 2: Runtime image
# ============================================================================
FROM pytorch/pytorch:2.10.0-cuda13.0-cudnn9-runtime

WORKDIR /app

# Install system dependencies (rarely changes - cached)
# g++ is needed for triton JIT compilation (torch.compile uses C++ compiler)
RUN apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg \
    libgl1 \
    libglib2.0-0 \
    git \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy SAM3 model EARLY - it's huge (~6GB) but rarely changes
# This layer gets cached and reused across code changes
COPY models/sam3 /models/sam3

# Copy exported requirements and install with pip (faster than poetry)
# Filter out packages already in pytorch base image (torch, nvidia CUDA libs, etc.)
COPY --from=requirements /build/requirements.txt ./
RUN grep -vE "^(torch|triton|nvidia-|numpy|pillow|sympy|networkx|fsspec|filelock|cffi|typing-extensions|pyyaml|markupsafe|jinja2|certifi|charset-normalizer|idna|urllib3|requests|packaging|pyparsing|mpmath|ipython|asttokens|prompt-toolkit|wcwidth|pygments|decorator|executing|stack-data|traitlets|matplotlib-inline|pexpect|ptyprocess|parso|jedi|pure-eval|psutil|click)" requirements.txt > requirements-filtered.txt && \
    mv requirements-filtered.txt requirements.txt
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install -r requirements.txt

# Apply patches to fix bugs in dependencies (e.g., transformers SAM3 video)
COPY patches/ ./patches/
RUN bash patches/fix_sam3_video_text_embeds.sh

# Copy application code LAST - changes most frequently
COPY app/ ./app/
COPY worker/ ./worker/

# Environment
ENV PYTHONPATH=/app
ENV CLOUD_MODEL_PATH=/models/sam3
ENV TOKENIZERS_PARALLELISM=false

CMD ["python", "-m", "worker", "--cloud"]
