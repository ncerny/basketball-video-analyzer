# backend/Dockerfile.worker
# Cloud worker image with SAM3 model baked in
#
# Build:
#   DOCKER_BUILDKIT=1 docker build --platform linux/amd64 -f Dockerfile.worker -t basketball-analyzer-worker .
#
# Run:
#   docker run --gpus all -e R2_ACCOUNT_ID=xxx -e R2_ACCESS_KEY_ID=xxx \
#     -e R2_SECRET_ACCESS_KEY=xxx -e R2_BUCKET_NAME=xxx \
#     basketball-analyzer-worker

# ============================================================================
# Stage 1: Export requirements from poetry (small, fast, cached)
# ============================================================================
FROM python:3.11-slim AS requirements

WORKDIR /build
RUN pip install poetry poetry-plugin-export

COPY pyproject.toml poetry.lock* ./
RUN poetry export --only main,ml,video --without-hashes -f requirements.txt -o requirements.txt
# Note: excludes api group (fastapi, uvicorn, alembic, rfdetr, norfair, runpod)

# ============================================================================
# Stage 2: Runtime image
# ============================================================================
FROM pytorch/pytorch:2.7.1-cuda12.8-cudnn9-runtime

WORKDIR /app

# Install system dependencies (rarely changes - cached)
# g++ is needed for triton JIT compilation (torch.compile uses C++ compiler)
RUN apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg \
    libgl1 \
    libglib2.0-0 \
    git \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy SAM3 model EARLY - it's huge (~6GB) but rarely changes
# This layer gets cached and reused across code changes
COPY models/sam3 /models/sam3

# Copy exported requirements and install with pip (faster than poetry)
# - Filter torch/torchvision (base image has ABI-compatible prebuilt versions)
# - Filter transformers (installed from git below)
# - Convert == to >= so pip uses existing packages if they satisfy requirements
#   (e.g., base has certifi 2026.1.4, requirements say >=2025.11.12, no reinstall needed)
COPY --from=requirements /build/requirements.txt ./
RUN grep -vE "^(transformers|torch[^a-z]|torchvision)" requirements.txt | \
    sed 's/==/>=/' > requirements-filtered.txt && \
    mv requirements-filtered.txt requirements.txt
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install --break-system-packages --upgrade-strategy only-if-needed -r requirements.txt

# Install transformers from git (SAM3 requires main branch, poetry git export format can fail)
# Use --no-deps to avoid reinstalling torch/torchvision (base image versions must match)
# Use --force-reinstall to ensure we get latest transformers from git, not cached
RUN pip install --break-system-packages --no-cache-dir --force-reinstall --no-deps \
    "transformers @ git+https://github.com/huggingface/transformers.git@main"

# Apply patches to fix bugs in dependencies (e.g., transformers SAM3 video)
COPY patches/ ./patches/
RUN bash patches/fix_sam3_video_text_embeds.sh && \
    bash patches/fix_sam3_torch_compile.sh

# Copy application code LAST - changes most frequently
COPY app/ ./app/
COPY worker/ ./worker/

# Environment
ENV PYTHONPATH=/app
ENV CLOUD_MODEL_PATH=/models/sam3
ENV TOKENIZERS_PARALLELISM=false

# torch.compile optimization settings
# Use multiple threads for compilation (default is 1)
ENV TORCHINDUCTOR_COMPILE_THREADS=8
# Enable graph caching to speed up subsequent runs
ENV TORCHINDUCTOR_FX_GRAPH_CACHE=1
ENV TORCHINDUCTOR_CACHE_DIR=/tmp/torch_compile_cache

CMD ["python", "-m", "worker", "--cloud"]
